##  python this_file.py##   change : input_movie as input movie file#            write_movie as output movie file#            sx0,sy0 sx1,sy1 sx2,sy2 sx3,sy3 as source coordinates to convert affine#import sysimport cv2import torchimport numpy as npdx0 =  650dy0 =  450dx1 =  750dy1 =  450dx2 =  750dy2 =  700dx3 =  650dy3 =  700#モデルの読み込みと設定model = torch.hub.load('ultralytics/yolov5','yolov5s')#model = torch.hub.load('ultralytics/yolov5','yolov5m')model.conf = 0.3	#検出の下限値#model.classes = [0]	#0:person クラスだけ#print(model.names)#動画ファイルの読み込み#camera = cv2.VideoCapture("2022_0121_090959_863.MOV")#input_movie = cv2.VideoCapture("../movie_processing/20230507_6.mp4")#write_movie = '20230507_6_birdview2.mp4'sx0 =  600sy0 =  105sx1 =  871sy1 =  102sx2 = 1500sy2 =  564sx3 =   46sy3 =  563input_movie = cv2.VideoCapture("../../../html/家/2023耀騎サッカー/20230617_練習試合/movie/MAH04086_s.mp4")write_movie = '../../../html/家/2023耀騎サッカー/20230617_練習試合/movie/MAH04086_s_birdview2.mov'sx0 =  440sy0 =  200sx1 =  840sy1 =  200sx2 = 1280sy2 =  720sx3 =    0sy3 =  720start_frame   = 0			#Start frameorig = np.float32([[sx0, sy0], [sx1, sy1], [sx2, sy2], [sx3,sy3]])tran = np.float32([[dx0, dy0], [dx1, dy1], [dx2, dy2], [dx3,dy3]])affine = cv2.getPerspectiveTransform(orig, tran)# Input moviefps = input_movie.get(cv2.CAP_PROP_FPS)w   = int(input_movie.get(cv2.CAP_PROP_FRAME_WIDTH))h   = int(input_movie.get(cv2.CAP_PROP_FRAME_HEIGHT))input_movie.set(cv2.CAP_PROP_POS_FRAMES, start_frame)# Output movie#fourcc    = cv2.VideoWriter_fourcc(*'H264')#fourcc    = cv2.VideoWriter_fourcc(*'X264')fourcc    = cv2.VideoWriter_fourcc(*'mp4v')out_movie = cv2.VideoWriter(write_movie, fourcc, fps, (w,h))#out_movie = cv2.VideoWriter(write_movie, -1, fps, (w,h))#動画すべてのフレームで処理をするwhile True:  ret, img = input_movie.read()  if not ret :    while cv2.waitKey(100) == -1:	#動画ファイルの最後ではキーを押すと終了      pass    break  results = model(img)		#default=640#  results = model(img, size=320)#  results = model(img, size=480)  #検出情報の描画  for *bb, conf, cls in results.xyxy[0]:    if model.names[int(cls)] == 'person' :      #cc  = (255,255,0)      cx  = int((bb[0] + bb[2])/2)      cy  = int((bb[1] + bb[3])/2)      p_x = (bb[0] + bb[2]) / 2      p_y = bb[3]      cc  = (int(img[cy][cx][0]), int(img[cy][cx][1]), int(img[cy][cx][2]))      #cv2.rectangle(      #    img,      #    (int(p_x)-2, int(p_y)-2),      #    (int(p_x)+2, int(p_y)+2),      #    color=cc,      #    thickness=2,      #    )      cv2.rectangle(          img,          (int(bb[0]), int(bb[1])),          (int(bb[2]), int(bb[3])),          color=cc,          thickness=1,          )      # bird view      #c = np.float32([[[p_x, p_y]]])      c2 = torch.tensor([[[p_x, p_y]]])      c  = c2.numpy()      dst = cv2.perspectiveTransform(c, affine)      cv2.rectangle(img, (int(dst[0][0][0])-5, int(dst[0][0][1])-5), (int(dst[0][0][0])+5, int(dst[0][0][1])+5), cc  ,-1)    if model.names[int(cls)] == 'sports ball' :      cc  = (0,0,255)      bb_x = (bb[0] + bb[2]) / 2      bb_y = (bb[1] + bb[3]) / 2      cv2.circle(          img,          center=(int(bb_x), int(bb_y)),          radius=10,          color=cc,          thickness=2,          )      # bird view      #c = np.float32([[[bb_x, bb_y]]])      c2 = torch.tensor([[[bb_x, bb_y]]])      c  = c2.numpy()      dst = cv2.perspectiveTransform(c, affine)      cv2.circle(img, center=(int(dst[0][0][0]), int(dst[0][0][1])), radius=6, color=cc, thickness=-1)  # src view frame  cv2.line(img, (sx0, sy0), (sx1, sy1), (0,255,255))  cv2.line(img, (sx1, sy1), (sx2, sy2), (0,255,255))  cv2.line(img, (sx2, sy2), (sx3, sy3), (0,255,255))  cv2.line(img, (sx3, sy3), (sx0, sy0), (0,255,255))  # bird view frame  cv2.rectangle(img, (dx0, dy0), (dx2, dy2), (0,0,0))  #動画出力  out_movie.write(img)  #表示  cv2.imshow('color',img)  #"q"を押すと終了  kk = cv2.waitKey(1)  if kk & 0xFF == ord('q'):    break  if kk != -1 :    while cv2.waitKey(100) == -1:      passout_movie.release()input_movie.release()cv2.destroyAllWindows()